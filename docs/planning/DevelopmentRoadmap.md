Development Roadmap: LTMC (Instructions for AI)Follow these steps sequentially to build the application. Ensure every file respects the 300-line limit.Step 1: Project ScaffoldingCreate the complete directory and file structure as defined in the Modular Project Structure document. All .py files should be created, even if empty.Populate requirements.txt with: fastapi, uvicorn, python-dotenv, sentence-transformers, faiss-cpu.Create a .env file with placeholder variables: EMBEDDING_MODEL_NAME=all-MiniLM-L6-v2, FAISS_INDEX_PATH=./data/ltmc.index, DATABASE_PATH=./data/ltmc.db.Step 2: Database Module (/database)connection.py: Implement a function to manage the SQLite connection and session.schema.py: Write a create_tables() function that executes the CREATE TABLE SQL statements for all four tables, using IF NOT EXISTS.dal.py: Create separate, single-purpose functions for each required database interaction (e.g., create_resource_in_db, get_chunks_by_vector_ids, create_chat_message, create_context_link). Use type hints for all function arguments and return values.Step 3: Core & Vector Store (/core, /vector_store)config.py: Create a Pydantic Settings class that loads variables from the .env file.vector_store/faiss_store.py: Implement a FaissStore class. It should have methods to add, search, save_index, and load_index. The constructor should initialize the FAISS index (or load it from the path specified in the config).services/embedding_service.py: Implement an EmbeddingService class. Its constructor should load the SentenceTransformer model specified in the config. It needs a single method, encode(text: str) -> List[float].core/lifecycle.py: Create startup_event and shutdown_event functions.startup: Calls create_tables, loads the embedding model, and loads the FAISS index.shutdown: Saves the FAISS index to disk.Step 4: Services (/services)chunking_service.py: Implement a function or class to perform text chunking (e.g., a simple paragraph splitter or a more advanced recursive splitter).resource_service.py: Implement the add_resource function. This will be the most complex service, orchestrating calls to the chunking service, embedding service, database DAL, and FaissStore.context_service.py: Implement the get_context_for_query function. This will orchestrate calls to the embedding service, FaissStore, and database DAL to retrieve context and log the interaction.Step 5: API Layer (/models, /api)models/schemas.py: Define all Pydantic models needed for the API request and response bodies as specified in the API Specification document.api/endpoints.py: Create a FastAPI APIRouter. Define the POST /resources and POST /context routes. Each route function should:Accept the Pydantic model as a request body.Call the appropriate function from the service layer.Return the result from the service layer, formatted according to the response schema.Step 6: Final Assembly (/main.py, /run.py)main.py:Create the main FastAPI app instance.Include the router from api.endpoints.Register the startup_event and shutdown_event handlers from core.lifecycle.run.py: Create a simple script that imports uvicorn and runs the app: uvicorn.run("ltms.main:app", host="0.0.0.0", port=8000, reload=True).
