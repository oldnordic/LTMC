#!/bin/bash

# Redis Orchestration Layer Testing Suite
# Comprehensive automated testing with Phase 0 validation

set -e  # Exit on any error

# Colors for output
RED='\\033[0;31m'
GREEN='\\033[0;32m'
YELLOW='\\033[0;33m'
BLUE='\\033[0;34m'
NC='\\033[0m' # No Color

# Configuration
PROJECT_ROOT="/home/feanor/Projects/lmtc"
TEST_DIR="$PROJECT_ROOT/tests/orchestration"
SERVER_STARTUP_TIMEOUT=30
TEST_TIMEOUT=300  # 5 minutes per test category

echo -e "${BLUE}ðŸ§ª Redis Orchestration Layer Testing Suite${NC}"
echo -e "${BLUE}===========================================${NC}"
echo ""

# Change to project directory and set PYTHONPATH
cd "$PROJECT_ROOT"
export PYTHONPATH="$PROJECT_ROOT:$PYTHONPATH"

# Ensure we have all required dependencies
echo -e "${YELLOW}ðŸ“¦ Checking dependencies...${NC}"
if ! command -v python &> /dev/null; then
    echo -e "${RED}âŒ Python not found${NC}"
    exit 1
fi

if ! python -c "import pytest" &> /dev/null; then
    echo -e "${RED}âŒ pytest not available${NC}"
    exit 1
fi

if ! python -c "import redis" &> /dev/null; then
    echo -e "${YELLOW}âš ï¸  Redis client not available - some tests may be skipped${NC}"
fi

echo -e "${GREEN}âœ… Dependencies check passed${NC}"
echo ""

# Kill any existing server processes
echo -e "${YELLOW}ðŸ§¹ Cleaning up existing processes...${NC}"
pkill -f "ltmc_mcp_server_http.py" || true
sleep 2

# PHASE 0: MANDATORY System Startup Validation
echo -e "${BLUE}ðŸš€ PHASE 0: System Startup Validation${NC}"
echo -e "${BLUE}====================================${NC}"

# Start server
echo -e "${YELLOW}  Starting LTMC HTTP server...${NC}"
python ltmc_mcp_server_http.py &
SERVER_PID=$!
echo "  Server PID: $SERVER_PID"

# Wait for server to start
echo -e "${YELLOW}  Waiting for server startup (max ${SERVER_STARTUP_TIMEOUT}s)...${NC}"
for i in $(seq 1 $SERVER_STARTUP_TIMEOUT); do
    if curl -f -s http://localhost:5050/health > /dev/null 2>&1; then
        echo -e "${GREEN}  âœ… Server started successfully${NC}"
        break
    fi
    
    if [ $i -eq $SERVER_STARTUP_TIMEOUT ]; then
        echo -e "${RED}  âŒ Server failed to start within ${SERVER_STARTUP_TIMEOUT} seconds${NC}"
        kill $SERVER_PID 2>/dev/null || true
        exit 1
    fi
    
    sleep 1
done

# Verify server health
echo -e "${YELLOW}  Verifying server health...${NC}"
if ! curl -f -s http://localhost:5050/health | grep -q "healthy"; then
    echo -e "${RED}  âŒ Server health check failed${NC}"
    kill $SERVER_PID 2>/dev/null || true
    exit 1
fi

# Verify all MCP tools available (expect at least 25, actual count is 28)
echo -e "${YELLOW}  Verifying MCP tools availability...${NC}"
TOOL_COUNT=$(curl -s http://localhost:5050/tools | jq -r '.count' 2>/dev/null || echo "0")
if [ "$TOOL_COUNT" -lt "25" ]; then
    echo -e "${RED}  âŒ Expected at least 25 MCP tools, found ${TOOL_COUNT}${NC}"
    kill $SERVER_PID 2>/dev/null || true
    exit 1
fi

echo -e "${GREEN}ðŸŽ‰ PHASE 0 VALIDATION SUCCESSFUL${NC}"
echo -e "${GREEN}  âœ… Server started and healthy${NC}"
echo -e "${GREEN}  âœ… All ${TOOL_COUNT} MCP tools available (meets minimum 25)${NC}"
echo -e "${GREEN}  âœ… Ready for orchestration testing${NC}"
echo ""

# Function to run test category with timeout
run_test_category() {
    local test_name=$1
    local test_file=$2
    local description=$3
    
    echo -e "${BLUE}ðŸ§ª $test_name${NC}"
    echo -e "${BLUE}$(echo "$test_name" | sed 's/./-/g')${NC}"
    
    # Check if test file exists
    if [ ! -f "$TEST_DIR/$test_file" ]; then
        echo -e "${YELLOW}  âš ï¸  Test file $test_file not found - skipping${NC}"
        return 0
    fi
    
    echo -e "${YELLOW}  $description${NC}"
    
    # Run test with timeout - add project root to Python path
    if timeout $TEST_TIMEOUT python -m pytest "$TEST_DIR/$test_file" -v --tb=short --asyncio-mode=auto -x; then
        echo -e "${GREEN}  âœ… $test_name PASSED${NC}"
        return 0
    else
        echo -e "${RED}  âŒ $test_name FAILED${NC}"
        return 1
    fi
}

# Track test results
TESTS_PASSED=0
TESTS_FAILED=0
FAILED_TESTS=()

# Test execution order (by priority)
echo -e "${BLUE}ðŸŽ¯ Running Test Categories (Priority Order)${NC}"
echo -e "${BLUE}===========================================${NC}"
echo ""

# CRITICAL: Backward Compatibility Tests
if run_test_category "BACKWARD COMPATIBILITY" "test_backward_compatibility.py" "Ensuring 25 MCP tools work unchanged"; then
    ((TESTS_PASSED++))
else
    ((TESTS_FAILED++))
    FAILED_TESTS+=("Backward Compatibility")
fi
echo ""

# HIGH: Service Integration Tests  
if run_test_category "SERVICE INTEGRATION" "test_service_integration.py" "Testing orchestration services integration"; then
    ((TESTS_PASSED++))
else
    ((TESTS_FAILED++))
    FAILED_TESTS+=("Service Integration")
fi
echo ""

# HIGH: Performance Benchmark Tests
if run_test_category "PERFORMANCE BENCHMARKS" "test_performance_benchmarks.py" "Measuring performance improvements"; then
    ((TESTS_PASSED++))
else
    ((TESTS_FAILED++))
    FAILED_TESTS+=("Performance Benchmarks")
fi
echo ""

# MEDIUM: Multi-Agent Coordination Tests
if run_test_category "MULTI-AGENT COORDINATION" "test_multi_agent_coordination.py" "Testing complex coordination scenarios"; then
    ((TESTS_PASSED++))
else
    ((TESTS_FAILED++))
    FAILED_TESTS+=("Multi-Agent Coordination")
fi
echo ""

# MEDIUM: Error Recovery Tests
if run_test_category "ERROR RECOVERY" "test_error_recovery.py" "Testing resilience and recovery"; then
    ((TESTS_PASSED++))
else
    ((TESTS_FAILED++))
    FAILED_TESTS+=("Error Recovery")
fi
echo ""

# Cleanup server
echo -e "${YELLOW}ðŸ§¹ Cleaning up server process...${NC}"
kill $SERVER_PID 2>/dev/null || true
wait $SERVER_PID 2>/dev/null || true
echo -e "${GREEN}  âœ… Server cleanup completed${NC}"
echo ""

# Test Results Summary
echo -e "${BLUE}ðŸ“Š TEST RESULTS SUMMARY${NC}"
echo -e "${BLUE}======================${NC}"
echo ""

TOTAL_TESTS=$((TESTS_PASSED + TESTS_FAILED))

echo -e "  Total Test Categories: $TOTAL_TESTS"
echo -e "  ${GREEN}Passed: $TESTS_PASSED${NC}"
echo -e "  ${RED}Failed: $TESTS_FAILED${NC}"
echo ""

if [ $TESTS_FAILED -eq 0 ]; then
    echo -e "${GREEN}ðŸŽ‰ ALL ORCHESTRATION TESTS PASSED${NC}"
    echo -e "${GREEN}=================================${NC}"
    echo -e "${GREEN}  âœ… Phase 0 validation successful${NC}"
    echo -e "${GREEN}  âœ… Backward compatibility maintained${NC}"
    echo -e "${GREEN}  âœ… Service integration working${NC}"
    echo -e "${GREEN}  âœ… Performance benchmarks met${NC}"
    echo -e "${GREEN}  âœ… Multi-agent coordination functional${NC}"
    echo -e "${GREEN}  âœ… Error recovery mechanisms validated${NC}"
    echo ""
    echo -e "${GREEN}âž¡ï¸  READY FOR ORCHESTRATION DEPLOYMENT${NC}"
    
    # Generate success report
    cat > "$PROJECT_ROOT/orchestration_test_report.md" << EOF
# Orchestration Testing Report - $(date)

## Test Results: âœ… ALL TESTS PASSED

### Test Categories Executed
- **Phase 0 Validation**: âœ… PASSED
- **Backward Compatibility**: âœ… PASSED  
- **Service Integration**: âœ… PASSED
- **Performance Benchmarks**: âœ… PASSED
- **Multi-Agent Coordination**: âœ… PASSED
- **Error Recovery**: âœ… PASSED

### Summary
- Total test categories: $TOTAL_TESTS
- Passed: $TESTS_PASSED
- Failed: $TESTS_FAILED

### Validation Status
âœ… System startup validation successful
âœ… All 25 MCP tools functional and unchanged
âœ… Orchestration services integration working
âœ… Performance requirements met
âœ… Multi-agent coordination validated
âœ… Error recovery mechanisms functional

### Deployment Readiness
ðŸŽ‰ **READY FOR ORCHESTRATION DEPLOYMENT**

The Redis orchestration layer has passed all critical tests and is ready for production deployment.
EOF
    
    echo -e "${GREEN}ðŸ“ Test report generated: orchestration_test_report.md${NC}"
    exit 0
    
else
    echo -e "${RED}âŒ ORCHESTRATION TESTS FAILED${NC}"
    echo -e "${RED}=============================${NC}"
    echo -e "${RED}  Failed test categories:${NC}"
    for failed_test in "${FAILED_TESTS[@]}"; do
        echo -e "${RED}    - $failed_test${NC}"
    done
    echo ""
    echo -e "${RED}ðŸš¨ CANNOT DEPLOY UNTIL ALL TESTS PASS${NC}"
    echo ""
    echo -e "${YELLOW}ðŸ“‹ Next Steps:${NC}"
    echo -e "  1. Review failed test logs above"
    echo -e "  2. Fix identified issues"
    echo -e "  3. Re-run orchestration test suite"
    echo -e "  4. Ensure all tests pass before deployment"
    
    # Generate failure report
    cat > "$PROJECT_ROOT/orchestration_test_report.md" << EOF
# Orchestration Testing Report - $(date)

## Test Results: âŒ TESTS FAILED

### Failed Test Categories
$(for failed_test in "${FAILED_TESTS[@]}"; do echo "- **$failed_test**: âŒ FAILED"; done)

### Summary
- Total test categories: $TOTAL_TESTS
- Passed: $TESTS_PASSED
- Failed: $TESTS_FAILED

### Action Required
ðŸš¨ **DEPLOYMENT BLOCKED**

The following issues must be resolved before orchestration deployment:
$(for failed_test in "${FAILED_TESTS[@]}"; do echo "- Fix issues in $failed_test tests"; done)

### Next Steps
1. Review test failure logs
2. Fix identified issues
3. Re-run orchestration test suite
4. Ensure all tests pass before deployment
EOF
    
    echo -e "${RED}ðŸ“ Failure report generated: orchestration_test_report.md${NC}"
    exit 1
fi